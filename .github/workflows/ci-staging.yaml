name: CI/CD - Staging Environment (Production-Grade)

on:
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Image tag to deploy (leave empty for latest from dev)"
        required: false
        type: string
      skip_tests:
        description: "Skip all tests (emergency deploys only)"
        required: false
        type: boolean
        default: false
      run_load_test:
        description: "Run load tests"
        required: false
        type: boolean
        default: true
      run_e2e_test:
        description: "Run E2E tests"
        required: false
        type: boolean
        default: true

concurrency:
  group: staging-deployment
  cancel-in-progress: false

permissions:
  contents: write
  pull-requests: write
  actions: write

env:
  # ===== Infrastructure =====
  REGISTRY: registry.digitalocean.com
  IMAGE_NAME: ai-incident-assistant
  CLUSTER_NAME: ai-incident-assistant

  # ===== Main staging (ArgoCD app that tracks main) =====
  STAGING_NAMESPACE: staging
  STAGING_URL: http://staging.174.138.120.13.nip.io
  ARGOCD_APP_NAME: ai-incident-staging

  # ===== Timeouts =====
  DEPLOYMENT_TIMEOUT: 10m
  ARGOCD_SYNC_TIMEOUT: 5m

  # ===== Load Test Config =====
  LOAD_TEST_DURATION: 5m
  LOAD_TEST_USERS: "50"

jobs:
  # ============================================
  # JOB 1: Validate & Prepare
  # ============================================
  prepare:
    name: Validate & Prepare
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      image_tag: ${{ steps.resolve-tag.outputs.image_tag }}
      short_sha: ${{ steps.resolve-tag.outputs.short_sha }}
      needs_deployment: ${{ steps.check-state.outputs.needs_deployment }}
      current_staging_tag: ${{ steps.check-state.outputs.current_tag }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

      - name: Resolve image tag
        id: resolve-tag
        shell: bash
        run: |
          if [[ -n "${{ inputs.image_tag }}" ]]; then
            IMAGE_TAG="${{ inputs.image_tag }}"
            echo "üì¶ Using provided image tag: $IMAGE_TAG"
          else
            IMAGE_TAG="$(yq '.images[0].newTag' infra/k8s/overlays/dev/kustomization.yaml)"
            echo "üì¶ Using dev image tag: $IMAGE_TAG"
          fi

          echo "image_tag=$IMAGE_TAG" >> "$GITHUB_OUTPUT"
          echo "short_sha=${IMAGE_TAG:0:7}" >> "$GITHUB_OUTPUT"

          echo "‚úÖ Resolved image tag: $IMAGE_TAG"

      - name: Check current staging state
        id: check-state
        shell: bash
        run: |
          CURRENT_TAG="$(yq '.images[0].newTag' infra/k8s/overlays/staging/kustomization.yaml)"
          TARGET_TAG="${{ steps.resolve-tag.outputs.image_tag }}"

          echo "current_tag=$CURRENT_TAG" >> "$GITHUB_OUTPUT"

          echo "üìä Staging State Check:"
          echo "  Current: $CURRENT_TAG"
          echo "  Target:  $TARGET_TAG"

          if [[ "$CURRENT_TAG" == "$TARGET_TAG" ]]; then
            echo "needs_deployment=false" >> "$GITHUB_OUTPUT"
            echo "‚úÖ Staging already at $TARGET_TAG"
          else
            echo "needs_deployment=true" >> "$GITHUB_OUTPUT"
            echo "üîÑ Deployment needed: $CURRENT_TAG ‚Üí $TARGET_TAG"
          fi

      - name: Verify images exist in registry
        shell: bash
        run: |
          echo "üîç Verifying Docker images exist..."

          # Note: Add actual registry verification if you have API access
          # For now, just log the images we expect
          echo "Backend:  ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:${{ steps.resolve-tag.outputs.image_tag }}"
          echo "Frontend: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:${{ steps.resolve-tag.outputs.image_tag }}"
          echo "‚úÖ Image verification complete"

  # ============================================
  # JOB 2: Create Deployment PR
  # ============================================
  create-pr:
    name: Create Deployment PR
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [prepare]
    if: needs.prepare.outputs.needs_deployment == 'true'
    outputs:
      pr_number: ${{ steps.create-pr.outputs.pr_number }}
      pr_url: ${{ steps.create-pr.outputs.pr_url }}
      branch_name: ${{ steps.branch.outputs.name }}
      commit_sha: ${{ steps.commit.outputs.sha }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Install tools
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          sudo snap install kubectl --classic

      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Create deployment branch
        id: branch
        shell: bash
        run: |
          BRANCH="deploy/staging-${{ needs.prepare.outputs.short_sha }}"
          git checkout -b "$BRANCH"
          echo "name=$BRANCH" >> "$GITHUB_OUTPUT"
          echo "‚úÖ Created branch: $BRANCH"

      - name: Update staging manifests (both images)
        shell: bash
        run: |
          echo "üìù Updating kustomization.yaml..."

          # Update ALL image tags (backend and frontend)
          yq -i '.images[].newTag = "${{ needs.prepare.outputs.image_tag }}"' infra/k8s/overlays/staging/kustomization.yaml

          echo "‚úÖ Updated manifests:"
          yq '.images' infra/k8s/overlays/staging/kustomization.yaml

      - name: Validate Kubernetes manifests
        shell: bash
        run: |
          echo "üîç Validating manifests with kustomize..."
          kubectl kustomize infra/k8s/overlays/staging > /tmp/staging-manifests.yaml

          echo "‚úÖ Manifests are valid"
          echo "üìä Resources to be deployed:"
          grep "^kind:" /tmp/staging-manifests.yaml | sort | uniq -c

      - name: Commit changes
        id: commit
        shell: bash
        run: |
          git add infra/k8s/overlays/staging/kustomization.yaml
          git commit -m "$(cat <<'EOF'
          chore(staging): deploy ${{ needs.prepare.outputs.image_tag }}

          Automated staging deployment
          - Backend:  ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:${{ needs.prepare.outputs.image_tag }}
          - Frontend: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:${{ needs.prepare.outputs.image_tag }}
          - Previous: ${{ needs.prepare.outputs.current_staging_tag }}
          - Triggered by: @${{ github.actor }}
          EOF
          )"

          COMMIT_SHA=$(git rev-parse HEAD)
          echo "sha=$COMMIT_SHA" >> "$GITHUB_OUTPUT"
          echo "‚úÖ Created commit: $COMMIT_SHA"

      - name: Push branch
        shell: bash
        run: |
          git push origin "${{ steps.branch.outputs.name }}"
          echo "‚úÖ Pushed branch to remote"

      - name: Create Pull Request
        id: create-pr
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          PR_BODY="$(cat <<'EOF'
          ## üöÄ Automated Staging Deployment

          ### üì¶ Image Tag
          ${{ needs.prepare.outputs.image_tag }}

          ### üîÑ Changes
          | Component | New Tag | Previous Tag |
          |-----------|---------|--------------|
          | Backend   | ${{ needs.prepare.outputs.image_tag }} | ${{ needs.prepare.outputs.current_staging_tag }} |
          | Frontend  | ${{ needs.prepare.outputs.image_tag }} | ${{ needs.prepare.outputs.current_staging_tag }} |

          ### üîó References
          - **Triggered by:** @${{ github.actor }}
          - **Workflow Run:** [View](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ### ‚ö° Deployment Process
          1. ‚úÖ Create PR (current step)
          2. ‚è≥ Deploy to preview namespace
          3. ‚è≥ Run E2E tests
          4. ‚è≥ Run load tests
          5. ‚è∏Ô∏è Manual approval required
          6. ‚è≥ Merge PR and sync to staging

          ---
          ‚ö†Ô∏è **Do not merge manually** - This PR will be automatically merged after tests pass and approval is granted.
          EOF
          )"

          PR_URL="$(gh pr create \
            --title "üöÄ Deploy to Staging: ${{ needs.prepare.outputs.short_sha }}" \
            --body "$PR_BODY" \
            --base main \
            --head "${{ steps.branch.outputs.name }}")"

          PR_NUMBER="$(gh pr view --json number -q '.number')"

          echo "pr_number=$PR_NUMBER" >> "$GITHUB_OUTPUT"
          echo "pr_url=$PR_URL" >> "$GITHUB_OUTPUT"
          echo "‚úÖ Created PR #$PR_NUMBER: $PR_URL"

  # ============================================
  # JOB 3: Deploy Preview Environment
  # ============================================
  deploy-preview:
    name: Deploy Preview Environment
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: [prepare, create-pr]
    if: needs.create-pr.result == 'success'
    outputs:
      preview_url: ${{ steps.info.outputs.preview_url }}
      app_name: ${{ steps.info.outputs.app_name }}
      preview_ns: ${{ steps.info.outputs.preview_ns }}

    steps:
      - name: Checkout PR commit
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.create-pr.outputs.commit_sha }}

      - name: Install tools
        run: |
          # Install yq for manifest manipulation
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version

          # Install kubectl
          sudo snap install kubectl --classic
          kubectl version --client

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup Kubernetes
        run: |
          mkdir -p $HOME/.kube
          doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_NAME }}
          kubectl version --client
          echo "‚úÖ Kubernetes configured"

      - name: Set preview environment info
        id: info
        shell: bash
        run: |
          SHORT="${{ needs.prepare.outputs.short_sha }}"
          PREVIEW_APP="staging-preview-$SHORT"
          PREVIEW_NS="staging-preview-$SHORT"
          PREVIEW_URL="http://preview-$SHORT.174.138.120.13.nip.io"

          echo "app_name=$PREVIEW_APP" >> "$GITHUB_OUTPUT"
          echo "preview_ns=$PREVIEW_NS" >> "$GITHUB_OUTPUT"
          echo "preview_url=$PREVIEW_URL" >> "$GITHUB_OUTPUT"

          echo "üìã Preview Environment:"
          echo "  App Name:  $PREVIEW_APP"
          echo "  Namespace: $PREVIEW_NS"
          echo "  URL:       $PREVIEW_URL"

      - name: Create preview namespace
        shell: bash
        run: |
          NS="${{ steps.info.outputs.preview_ns }}"

          echo "üì¶ Creating preview namespace: $NS"

          kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -
          kubectl label namespace "$NS" environment=staging-preview preview=true --overwrite

          echo "‚úÖ Namespace ready"

      - name: Copy secrets to preview namespace
        shell: bash
        run: |
          SOURCE_NS="${{ env.STAGING_NAMESPACE }}"
          TARGET_NS="${{ steps.info.outputs.preview_ns }}"

          echo "üîê Copying secrets from $SOURCE_NS to $TARGET_NS..."

          # Copy postgres-secret
          kubectl get secret postgres-secret -n "$SOURCE_NS" -o yaml | \
            sed "s/namespace: $SOURCE_NS/namespace: $TARGET_NS/" | \
            kubectl apply -f -

          # Copy backend-secret
          kubectl get secret backend-secret -n "$SOURCE_NS" -o yaml | \
            sed "s/namespace: $SOURCE_NS/namespace: $TARGET_NS/" | \
            kubectl apply -f -

          # Verify secrets exist
          echo "‚úÖ Secrets copied:"
          kubectl get secrets -n "$TARGET_NS" | grep -E "postgres-secret|backend-secret"

      - name: Build and apply preview manifests
        shell: bash
        run: |
          TARGET_NS="${{ steps.info.outputs.preview_ns }}"

          echo "üèóÔ∏è Building manifests for preview environment..."

          # Temporarily modify namespace in kustomization for preview
          cd infra/k8s/overlays/staging

          # Show original namespace
          echo "Original namespace:"
          grep "^namespace:" kustomization.yaml

          # Create a temporary kustomization with preview namespace
          cp kustomization.yaml kustomization.yaml.backup

          # Update namespace using yq (reliably modifies YAML)
          yq eval ".namespace = \"$TARGET_NS\"" -i kustomization.yaml

          # Verify the change
          echo "Modified namespace to:"
          grep "^namespace:" kustomization.yaml

          # Build manifests
          kubectl kustomize . > /tmp/preview-manifests.yaml

          # Modify the ingress hostname for preview environment
          # Change staging.174.138.120.13.nip.io to preview-SHORTSHA.174.138.120.13.nip.io
          SHORT_SHA="${{ needs.prepare.outputs.short_sha }}"
          PREVIEW_HOST="preview-$SHORT_SHA.174.138.120.13.nip.io"

          echo "Updating ingress hostname to: $PREVIEW_HOST"
          sed -i "s/staging\.174\.138\.120\.13\.nip\.io/$PREVIEW_HOST/g" /tmp/preview-manifests.yaml

          # Verify the ingress change
          echo "Ingress configuration:"
          grep -A2 "host:" /tmp/preview-manifests.yaml | head -5

          # Restore original kustomization
          mv kustomization.yaml.backup kustomization.yaml

          cd -

          # Show summary of what will be applied
          echo "Resources to be applied:"
          grep -E "^kind:|^  name:|^  namespace:" /tmp/preview-manifests.yaml | head -20

          # Check manifest file size
          MANIFEST_SIZE=$(wc -l /tmp/preview-manifests.yaml | awk '{print $1}')
          echo "Manifest file has $MANIFEST_SIZE lines"

          if [[ $MANIFEST_SIZE -lt 10 ]]; then
            echo "‚ùå ERROR: Manifest file seems empty or too small!"
            cat /tmp/preview-manifests.yaml
            exit 1
          fi

          # Apply to preview namespace
          echo "Applying manifests to $TARGET_NS..."
          kubectl apply -f /tmp/preview-manifests.yaml --validate=true --dry-run=client || {
            echo "‚ùå Dry-run validation failed!"
            exit 1
          }

          kubectl apply -f /tmp/preview-manifests.yaml

          # Verify resources were created
          echo "Verifying resources in $TARGET_NS:"
          kubectl get all -n "$TARGET_NS" || echo "WARNING: No resources found yet"

          echo "‚úÖ Manifests applied to $TARGET_NS"

      - name: Wait for deployments to be created
        shell: bash
        run: |
          NS="${{ steps.info.outputs.preview_ns }}"

          echo "‚è≥ Waiting for deployments to be created in $NS..."

          for i in {1..60}; do
            # Check if resources exist (returns 0 if exists, 1 if not)
            kubectl get deployment backend -n "$NS" >/dev/null 2>&1 && BACKEND_EXISTS="true" || BACKEND_EXISTS="false"
            kubectl get deployment frontend -n "$NS" >/dev/null 2>&1 && FRONTEND_EXISTS="true" || FRONTEND_EXISTS="false"
            kubectl get statefulset postgres -n "$NS" >/dev/null 2>&1 && POSTGRES_EXISTS="true" || POSTGRES_EXISTS="false"

            echo "[$i/60] Backend=$BACKEND_EXISTS Frontend=$FRONTEND_EXISTS Postgres=$POSTGRES_EXISTS"

            if [[ "$BACKEND_EXISTS" == "true" && "$FRONTEND_EXISTS" == "true" && "$POSTGRES_EXISTS" == "true" ]]; then
              echo "‚úÖ All resources created!"
              exit 0
            fi

            if [[ $i -eq 60 ]]; then
              echo "‚ùå Timeout waiting for resources"
              echo "Checking for errors..."
              kubectl get events -n "$NS" --sort-by='.lastTimestamp' | tail -20
              exit 1
            fi

            sleep 5
          done

      - name: Check deployment status
        shell: bash
        run: |
          NS="${{ steps.info.outputs.preview_ns }}"

          echo "üìä Checking deployment status..."

          # Check for any pod errors
          echo "Pods in $NS:"
          kubectl get pods -n "$NS" -o wide

          # Check events for errors
          echo ""
          echo "Recent events:"
          kubectl get events -n "$NS" --sort-by='.lastTimestamp' | tail -10

      - name: Wait for deployments to be ready
        shell: bash
        run: |
          NS="${{ steps.info.outputs.preview_ns }}"

          echo "‚è≥ Waiting for deployments to be ready..."

          # Wait for postgres first (backend depends on it)
          echo "1/3 Waiting for postgres..."
          kubectl rollout status statefulset/postgres -n "$NS" --timeout=${{ env.DEPLOYMENT_TIMEOUT }}

          # Wait for backend
          echo "2/3 Waiting for backend..."
          kubectl rollout status deployment/backend -n "$NS" --timeout=${{ env.DEPLOYMENT_TIMEOUT }}

          # Wait for frontend
          echo "3/3 Waiting for frontend..."
          kubectl rollout status deployment/frontend -n "$NS" --timeout=${{ env.DEPLOYMENT_TIMEOUT }}

          echo "‚úÖ All deployments ready!"

      - name: Verify preview deployment health
        shell: bash
        run: |
          NS="${{ steps.info.outputs.preview_ns }}"

          echo "üè• Health Check:"

          # Get pod status
          kubectl get pods -n "$NS"

          # Check backend logs for startup
          echo ""
          echo "Backend logs (last 10 lines):"
          kubectl logs -n "$NS" deployment/backend --tail=10 || echo "No logs available yet"

          # Verify all pods are running
          READY_PODS=$(kubectl get pods -n "$NS" --field-selector=status.phase=Running --no-headers | wc -l)
          TOTAL_PODS=$(kubectl get pods -n "$NS" --no-headers | wc -l)

          echo ""
          echo "üìä Status: $READY_PODS/$TOTAL_PODS pods running"

          if [[ $READY_PODS -lt $TOTAL_PODS ]]; then
            echo "‚ö†Ô∏è Warning: Not all pods are running"
          else
            echo "‚úÖ All pods running!"
          fi

      - name: Update PR with preview status
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          STATUS="${{ job.status }}"
          NS="${{ steps.info.outputs.preview_ns }}"
          PREVIEW_URL="${{ steps.info.outputs.preview_url }}"

          if [[ "$STATUS" == "success" ]]; then
            EMOJI="‚úÖ"
            MESSAGE="Preview environment deployed successfully!"
          else
            EMOJI="‚ùå"
            MESSAGE="Preview deployment failed. Check workflow logs."
          fi

          COMMENT_BODY="$(cat <<EOF
          ### $EMOJI Preview Deployment $STATUS

          **Namespace:** \`$NS\`
          **URL:** $PREVIEW_URL

          #### Resources
          \`\`\`
          $(kubectl get pods -n "$NS" 2>/dev/null || echo "Failed to get pods")
          \`\`\`

          $MESSAGE
          EOF
          )"

          gh pr comment "${{ needs.create-pr.outputs.pr_number }}" --body "$COMMENT_BODY"

  # ============================================
  # JOB 4: E2E Tests
  # ============================================
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [prepare, create-pr, deploy-preview]
    if: inputs.skip_tests != true && inputs.run_e2e_test != false && needs.deploy-preview.result == 'success'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup Kubernetes
        run: |
          mkdir -p $HOME/.kube
          doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_NAME }}
          echo "‚úÖ Kubernetes configured"

      - name: Install Argo CLI
        run: |
          echo "üì¶ Installing Argo Workflows CLI v3.5.4..."
          curl -sLO "https://github.com/argoproj/argo-workflows/releases/download/v3.5.4/argo-linux-amd64.gz"
          gunzip argo-linux-amd64.gz
          chmod +x argo-linux-amd64
          sudo mv argo-linux-amd64 /usr/local/bin/argo
          argo version
          echo "‚úÖ Argo CLI ready"

      - name: Run E2E workflow
        id: e2e
        shell: bash
        run: |
          echo "üß™ Starting E2E tests..."

          # Submit workflow and get name (without logs)
          WORKFLOW_NAME="$(argo submit infra/argo-workflows/e2e-tests.yaml \
            -n argo \
            --parameter image_tag=${{ needs.prepare.outputs.image_tag }} \
            --parameter target_url=${{ needs.deploy-preview.outputs.preview_url }} \
            --parameter namespace=${{ needs.deploy-preview.outputs.preview_ns }} \
            -o name)"

          echo "workflow_name=$WORKFLOW_NAME" >> "$GITHUB_OUTPUT"
          echo "‚úÖ E2E workflow: $WORKFLOW_NAME"

          # Wait for workflow and stream logs separately
          argo wait "$WORKFLOW_NAME" -n argo
          argo logs "$WORKFLOW_NAME" -n argo

      - name: Check E2E result
        if: always()
        shell: bash
        run: |
          STATUS="$(argo get "${{ steps.e2e.outputs.workflow_name }}" -n argo -o json | jq -r '.status.phase')"

          echo "üìä E2E Test Result: $STATUS"

          if [[ "$STATUS" != "Succeeded" ]]; then
            echo "‚ùå E2E tests failed!"
            argo logs "${{ steps.e2e.outputs.workflow_name }}" -n argo || true
            exit 1
          fi

          echo "‚úÖ E2E tests passed!"

      - name: Update PR with E2E results
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          STATUS="${{ job.status }}"

          if [[ "$STATUS" == "success" ]]; then
            EMOJI="‚úÖ"
            MESSAGE="E2E tests passed!"
          else
            EMOJI="‚ùå"
            MESSAGE="E2E tests failed. Check workflow logs for details."
          fi

          COMMENT_BODY="$(cat <<EOF
          ### $EMOJI E2E Tests $STATUS

          $MESSAGE

          **Workflow:** \`${{ steps.e2e.outputs.workflow_name }}\`
          EOF
          )"

          gh pr comment "${{ needs.create-pr.outputs.pr_number }}" --body "$COMMENT_BODY"

  # ============================================
  # JOB 5: Load Tests
  # ============================================
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 40
    needs: [prepare, create-pr, deploy-preview, e2e-tests]
    if: |
      inputs.skip_tests != true &&
      inputs.run_load_test != false &&
      needs.deploy-preview.result == 'success' &&
      (needs.e2e-tests.result == 'success' || needs.e2e-tests.result == 'skipped')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup Kubernetes
        run: |
          mkdir -p $HOME/.kube
          doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_NAME }}
          echo "‚úÖ Kubernetes configured"

      - name: Install Argo CLI
        run: |
          echo "üì¶ Installing Argo Workflows CLI v3.5.4..."
          curl -sLO "https://github.com/argoproj/argo-workflows/releases/download/v3.5.4/argo-linux-amd64.gz"
          gunzip argo-linux-amd64.gz
          chmod +x argo-linux-amd64
          sudo mv argo-linux-amd64 /usr/local/bin/argo
          argo version
          echo "‚úÖ Argo CLI ready"

      - name: Run Load workflow
        id: load
        shell: bash
        run: |
          echo "üìä Starting load tests..."
          echo "  Duration: ${{ env.LOAD_TEST_DURATION }}"
          echo "  Users: ${{ env.LOAD_TEST_USERS }}"

          # Submit workflow and get name (without logs)
          WORKFLOW_NAME="$(argo submit infra/argo-workflows/load-tests.yaml \
            -n argo \
            --parameter image_tag=${{ needs.prepare.outputs.image_tag }} \
            --parameter target_url=${{ needs.deploy-preview.outputs.preview_url }} \
            --parameter namespace=${{ needs.deploy-preview.outputs.preview_ns }} \
            --parameter duration=${{ env.LOAD_TEST_DURATION }} \
            --parameter users=${{ env.LOAD_TEST_USERS }} \
            -o name)"

          echo "workflow_name=$WORKFLOW_NAME" >> "$GITHUB_OUTPUT"
          echo "‚úÖ Load test workflow: $WORKFLOW_NAME"

          # Wait for workflow and stream logs separately
          argo wait "$WORKFLOW_NAME" -n argo
          argo logs "$WORKFLOW_NAME" -n argo

      - name: Check Load test result
        if: always()
        shell: bash
        run: |
          STATUS="$(argo get "${{ steps.load.outputs.workflow_name }}" -n argo -o json | jq -r '.status.phase')"

          echo "üìä Load Test Result: $STATUS"

          if [[ "$STATUS" != "Succeeded" ]]; then
            echo "‚ùå Load tests failed!"
            argo logs "${{ steps.load.outputs.workflow_name }}" -n argo || true
            exit 1
          fi

          echo "‚úÖ Load tests passed!"

      - name: Update PR with load test results
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          STATUS="${{ job.status }}"

          if [[ "$STATUS" == "success" ]]; then
            EMOJI="‚úÖ"
            MESSAGE="Load tests passed!"
          else
            EMOJI="‚ùå"
            MESSAGE="Load tests failed. Check workflow logs for details."
          fi

          COMMENT_BODY="$(cat <<EOF
          ### $EMOJI Load Tests $STATUS

          $MESSAGE

          **Workflow:** \`${{ steps.load.outputs.workflow_name }}\`
          **Config:** ${{ env.LOAD_TEST_USERS }} users, ${{ env.LOAD_TEST_DURATION }} duration
          EOF
          )"

          gh pr comment "${{ needs.create-pr.outputs.pr_number }}" --body "$COMMENT_BODY"

  # ============================================
  # JOB 6: Approval & Promote to Staging
  # ============================================
  approve-and-promote:
    name: Approve & Promote to Staging
    runs-on: ubuntu-latest
    timeout-minutes: 90
    needs: [prepare, create-pr, deploy-preview, e2e-tests, load-tests]
    if: |
      needs.create-pr.result == 'success' &&
      needs.deploy-preview.result == 'success' &&
      (needs.e2e-tests.result == 'success' || needs.e2e-tests.result == 'skipped') &&
      (needs.load-tests.result == 'success' || needs.load-tests.result == 'skipped')
    environment:
      name: staging
      url: ${{ env.STAGING_URL }}

    steps:
      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup Kubernetes
        run: |
          mkdir -p $HOME/.kube
          doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_NAME }}
          echo "‚úÖ Kubernetes configured"

      - name: Merge PR (after manual approval)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          PR="${{ needs.create-pr.outputs.pr_number }}"

          echo "‚úÖ Manual approval received!"
          echo "üîÄ Merging PR #$PR..."

          gh pr merge "$PR" --squash --delete-branch

          echo "‚úÖ PR merged successfully"

      - name: Wait for main branch to update
        shell: bash
        run: |
          echo "‚è≥ Waiting for main branch to update..."
          sleep 15
          echo "‚úÖ Branch should be updated"

      - name: Sync main staging ArgoCD app
        shell: bash
        run: |
          APP="${{ env.ARGOCD_APP_NAME }}"

          echo "üîÑ Syncing ArgoCD app: $APP"

          # Force hard refresh
          kubectl patch application "$APP" -n argocd --type merge \
            -p '{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' || true

          sleep 5

          # Wait for sync
          echo "‚è≥ Waiting for sync to complete..."
          for i in {1..60}; do
            SYNC="$(kubectl get app "$APP" -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown")"
            HEALTH="$(kubectl get app "$APP" -n argocd -o jsonpath='{.status.health.status}' 2>/dev/null || echo "Unknown")"

            echo "[$i/60] Sync=$SYNC Health=$HEALTH"

            if [[ "$SYNC" == "Synced" && "$HEALTH" == "Healthy" ]]; then
              echo "‚úÖ Main staging app synced & healthy!"
              exit 0
            fi

            if [[ $i -eq 60 ]]; then
              echo "‚ùå Timeout waiting for sync"
              kubectl get app "$APP" -n argocd -o yaml || true
              exit 1
            fi

            sleep 5
          done

      - name: Verify staging deployment
        shell: bash
        run: |
          NS="${{ env.STAGING_NAMESPACE }}"

          echo "üîç Verifying staging deployment..."

          # Check deployment status
          kubectl get deployments -n "$NS"

          # Check pod status
          echo ""
          kubectl get pods -n "$NS"

          # Verify image tags
          echo ""
          echo "üì¶ Verifying image tags..."
          BACKEND_IMAGE=$(kubectl get deployment backend -n "$NS" -o jsonpath='{.spec.template.spec.containers[0].image}')
          FRONTEND_IMAGE=$(kubectl get deployment frontend -n "$NS" -o jsonpath='{.spec.template.spec.containers[0].image}')

          echo "Backend:  $BACKEND_IMAGE"
          echo "Frontend: $FRONTEND_IMAGE"

          EXPECTED_TAG="${{ needs.prepare.outputs.image_tag }}"
          if [[ "$BACKEND_IMAGE" == *"$EXPECTED_TAG"* && "$FRONTEND_IMAGE" == *"$EXPECTED_TAG"* ]]; then
            echo "‚úÖ Image tags verified!"
          else
            echo "‚ùå Image tag mismatch!"
            exit 1
          fi

      - name: Cleanup preview environment
        if: always()
        shell: bash
        run: |
          PREVIEW_NS="${{ needs.deploy-preview.outputs.preview_ns }}"

          echo "üßπ Cleaning up preview environment..."

          # Delete preview namespace (this will delete all resources in it)
          kubectl delete namespace "$PREVIEW_NS" --wait=false || true

          echo "‚úÖ Cleanup initiated for $PREVIEW_NS"

  # ============================================
  # JOB 7: Rollback on Failure
  # ============================================
  rollback:
    name: Rollback on Failure
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [prepare, create-pr, deploy-preview, e2e-tests, load-tests, approve-and-promote]
    if: |
      always() &&
      (needs.deploy-preview.result == 'failure' ||
       needs.e2e-tests.result == 'failure' ||
       needs.load-tests.result == 'failure' ||
       needs.approve-and-promote.result == 'failure')

    steps:
      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup Kubernetes
        run: |
          mkdir -p $HOME/.kube
          doctl kubernetes cluster kubeconfig save ${{ env.CLUSTER_NAME }}
          echo "‚úÖ Kubernetes configured"

      - name: Cleanup preview namespace
        if: needs.deploy-preview.result == 'success'
        shell: bash
        run: |
          PREVIEW_NS="${{ needs.deploy-preview.outputs.preview_ns }}"

          echo "üßπ Cleaning up failed preview deployment..."
          kubectl delete namespace "$PREVIEW_NS" --wait=false || true
          echo "‚úÖ Cleanup initiated"

      - name: Close PR
        if: needs.create-pr.result == 'success'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          PR="${{ needs.create-pr.outputs.pr_number }}"

          echo "üî¥ Closing failed deployment PR #$PR..."

          COMMENT_BODY="$(cat <<EOF
          ‚ùå **Deployment Failed**

          This PR is being closed due to deployment failure.

          **Failed Stage:**
          - Deploy Preview: ${{ needs.deploy-preview.result }}
          - E2E Tests: ${{ needs.e2e-tests.result }}
          - Load Tests: ${{ needs.load-tests.result }}
          - Promote: ${{ needs.approve-and-promote.result }}

          Please review the [workflow logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) and fix the issues before retrying.
          EOF
          )"

          gh pr comment "$PR" --body "$COMMENT_BODY"

          gh pr close "$PR"

          # Delete the branch
          git push origin --delete "${{ needs.create-pr.outputs.branch_name }}" || true

          echo "‚úÖ PR closed and branch deleted"

  # ============================================
  # JOB 8: Notifications
  # ============================================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [prepare, create-pr, deploy-preview, e2e-tests, load-tests, approve-and-promote, rollback]
    if: always()

    steps:
      - name: Determine deployment status
        id: status
        shell: bash
        run: |
          if [[ "${{ needs.approve-and-promote.result }}" == "success" ]]; then
            echo "emoji=‚úÖ" >> "$GITHUB_OUTPUT"
            echo "status=SUCCESS" >> "$GITHUB_OUTPUT"
            echo "message=Staging deployment completed successfully!" >> "$GITHUB_OUTPUT"
            echo "color=good" >> "$GITHUB_OUTPUT"
          elif [[ "${{ needs.create-pr.result }}" == "skipped" ]]; then
            echo "emoji=‚ÑπÔ∏è" >> "$GITHUB_OUTPUT"
            echo "status=SKIPPED" >> "$GITHUB_OUTPUT"
            echo "message=No deployment needed - staging already at target version" >> "$GITHUB_OUTPUT"
            echo "color=warning" >> "$GITHUB_OUTPUT"
          else
            echo "emoji=‚ùå" >> "$GITHUB_OUTPUT"
            echo "status=FAILED" >> "$GITHUB_OUTPUT"
            echo "message=Staging deployment failed!" >> "$GITHUB_OUTPUT"
            echo "color=danger" >> "$GITHUB_OUTPUT"
          fi

      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "text": "${{ steps.status.outputs.emoji }} Staging Pipeline: ${{ steps.status.outputs.status }}",
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "${{ steps.status.outputs.emoji }} Staging Deployment Pipeline"
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Status:*\n${{ steps.status.outputs.status }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Image Tag:*\n`${{ needs.prepare.outputs.image_tag || 'N/A' }}`"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Triggered By:*\n${{ github.actor }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Environment:*\nStaging"
                    }
                  ]
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "${{ steps.status.outputs.message }}"
                  }
                },
                {
                  "type": "context",
                  "elements": [
                    {
                      "type": "mrkdwn",
                      "text": "Deploy: ${{ needs.deploy-preview.result || 'skipped' }} | E2E: ${{ needs.e2e-tests.result || 'skipped' }} | Load: ${{ needs.load-tests.result || 'skipped' }} | Promote: ${{ needs.approve-and-promote.result || 'skipped' }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|üîó View Workflow Run>"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
